{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Meaningful Insights from Engaging Posts\n",
    "People visit several online communities throughout the week. During the course of the week, posts within these communities receive lots of engagement from other users. Usually the posts with lots of engagement have lots of comments and shares throughout social media. The goal of this project is to examine which posts receive the most comments due to factors within our control. We'll be using data from Hackernews.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Outline\n",
    "#### 1. Introduction:\n",
    "Introduction to the project and our why.\n",
    "#### 2. Project Goals\n",
    "The goals that help us answer our why.\n",
    "#### 3. Data Analysis\n",
    "Working with the data to uncover insights and analyzing patterns.\n",
    "#### 4. Conclusion\n",
    "What conclusions our project has revealed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "##### 1.1 What is Hacker News, Who Visits Hacker News, and why evaluate Hacker News?\n",
    "#### 1.1.1 What is Hacker News?\n",
    "<a href=\"https://news.ycombinator.com/\">Hacker News</a> is a social news site focused on entrepreneurship and technology and is owned by <a href=\"https://www.ycombinator.com/Ycombinator\">Ycombinator</a>. Users can comment, share, and upvote/downvote posts in a similar fashion to <a href=\"https://reddit.com\">reddit.</a>\n",
    "\n",
    "#### 1.1.2 Who Visits Hacker News?\n",
    "People who are interested in technology and entrepreneurship are the main users of HackerNews. The site receives over half a million visitors monthly. <a href=\"https://app.neilpatel.com/en/traffic_analyzer/overview?lang=en&locId=2840&domain=news.ycombinator.com\"> Source</a>.\n",
    "\n",
    "#### 1.1.3 Why Evaluate Hacker News?\n",
    "Since Hacker News is an established site, with an easy to use voting system, we can examine what kind of posts would create the most visibility through comments or upvotes. We can also examine which day(s) and time(s) would be the best to post in order to receive more shares and comments on the platform. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Project Goals \n",
    "\n",
    "Hacker News is a popular news outlet similar in scope to reddit for tech and tech related news. Users often create threads using hashtags #AskHN or #ShowHN. #AskHN posts ask users within the community a specific question, such as \"What is the best tech stack for an online store?\". Similarly #ShowHN posts show the community a project, product, or something interesting and eye catching. \n",
    "\n",
    "Because of the popularity of these posts, we want to analyze which posts create more engagement on average. We'd also like to analyze the other factors that may lead to engagement such as: time of post, framing of header, etc\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "- <b>Do #AskHN or #ShowHN posts receive more comments on average?\n",
    "- <b>Does posting at a certain time generate more comments on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analysis Section\n",
    "### 3.1 Introduction to the Data\n",
    "The data set we're working with was reduced from close to 300,000 rows down to around 20,000 rows. This was done by removing posts that did not receive any comments, and then randomly sampling from the remaining posts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# Reading in hacker news data set as a list of lists\n",
    "opened_file = open(\"hacker_news.csv\", encoding=\"utf-8\")\n",
    "read_file = reader(opened_file)\n",
    "hn_raw = list(read_file)\n",
    "headers = hn_raw[0] # Headers of the dataset\n",
    "\n",
    "# Removing headers from dataset\n",
    "hn = hn_raw[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring some data points from dataset with headers\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "hn[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Summary of Data\n",
    "The data set contains the title of the posts, the number comments on the post, and the date and time the post was created. Now let's explore the number of comments for each type of post from AskHN and ShowHN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Separating AskHN posts from ShowHN posts\n",
    "The first thing that needs to be done is to identify posts that begin with AskHN or ShowHN. After identifying them, we can then place each datapoint into a separate list for analysis. We also need to account for other posts that are not either. We should have three separate lists:\n",
    "- AskHN posts\n",
    "- ShowHN posts\n",
    "- Other posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three empty lists\n",
    "ask_posts =[]\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "# Categorizing posts by titles \n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith(\"ask hn\"):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Which posts receive higher avg amount of comments?\n",
    "\n",
    "To find out which posts receive the highest number of comments, we can compare the avg number of comments for each sub-category \"ask hn\" and \"show hn\".\n",
    "#### 3.4.1 Finding Avg Number of Comments for AskHN and ShowHN Posts\n",
    "All the posts have been separated into different lists. Now we'll calculate the avg number of comments received per post based on their category (AskHN, ShowHN, Other). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "# Finding avg number of comments for AskHN posts\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    comment = int(row[4])\n",
    "    total_ask_comments += comment\n",
    "\n",
    "# Computing avg number of comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "# Finding ttl comments in show_posts list\n",
    "total_show_comments = 0\n",
    "\n",
    "# Finding Avg posts for ShowHN Posts\n",
    "for row in show_posts:\n",
    "    scomment = int(row[4])\n",
    "    total_show_comments += scomment\n",
    "    \n",
    "# Finding the avg \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Average Number of comments based on Category\n",
    "AskHN posts from our sample receive on average 14 comments. ShowHN posts receive around 10 comments per post. Because AskHN posts receive a higher average amount of comments, we'll focus only on these now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here on we will shift our analysis and focus only on \"Ask Hn\" post data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Determining the best time to post for engagement\n",
    "We want to check and see if there's any correlation between the time a post was made and the number of comments it receives. If we find that posting at a certain time elicits more comments, we'll have an advantage of knowing when to post. \n",
    "#### We will perform this analysis using the following steps:\n",
    "<ol>\n",
    "<li> Calculate the amount of ask posts created in each hour of the day, along with comments received.</li>\n",
    "<li> Calculate the average number of comments ask posts received by hour created </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'09': 251,\n",
       " '13': 1253,\n",
       " '10': 793,\n",
       " '14': 1416,\n",
       " '16': 1814,\n",
       " '23': 543,\n",
       " '12': 687,\n",
       " '17': 1146,\n",
       " '15': 4477,\n",
       " '21': 1745,\n",
       " '20': 1722,\n",
       " '02': 1381,\n",
       " '18': 1439,\n",
       " '03': 421,\n",
       " '05': 464,\n",
       " '19': 1188,\n",
       " '01': 683,\n",
       " '22': 479,\n",
       " '08': 492,\n",
       " '04': 337,\n",
       " '00': 447,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '11': 641}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating amount of ask posts created each hour and comments on the post. \n",
    "import datetime as dt\n",
    "\n",
    " \n",
    "result_list = [] # will be a list of lists\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    pcomment = int(row[4])\n",
    "    #list for the two variables above\n",
    "    ask_list = [created_at, pcomment]\n",
    "    result_list.append(ask_list)\n",
    "    \n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    dt_object = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    hour = dt.datetime.strftime(dt_object, \"%H\")\n",
    "    \n",
    "    #if the hour isn't a key in counts_by_hour\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1] #the comment column created for pcomment var\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "\n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.58],\n",
       " ['13', 14.74],\n",
       " ['10', 13.44],\n",
       " ['14', 13.23],\n",
       " ['16', 16.8],\n",
       " ['23', 7.99],\n",
       " ['12', 9.41],\n",
       " ['17', 11.46],\n",
       " ['15', 38.59],\n",
       " ['21', 16.01],\n",
       " ['20', 21.52],\n",
       " ['02', 23.81],\n",
       " ['18', 13.2],\n",
       " ['03', 7.8],\n",
       " ['05', 10.09],\n",
       " ['19', 10.8],\n",
       " ['01', 11.38],\n",
       " ['22', 6.75],\n",
       " ['08', 10.25],\n",
       " ['04', 7.17],\n",
       " ['00', 8.13],\n",
       " ['06', 9.02],\n",
       " ['07', 7.85],\n",
       " ['11', 11.05]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating avg number of comments per post for each hour of the day\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg = (comments_by_hour[hour] / counts_by_hour[hour])\n",
    "    avg_by_hour.append([hour, round((avg),2)])\n",
    "\n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Arranging and Printing Average Number of Comments Per Hour\n",
    "Now that we have a list of lists with our average amount of comments per hour, we want to arrange it in a way to output the number of comments in descending order. We only want to focus on the times where posts received the most comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.58, '09'], [14.74, '13'], [13.44, '10'], [13.23, '14'], [16.8, '16'], [7.99, '23'], [9.41, '12'], [11.46, '17'], [38.59, '15'], [16.01, '21'], [21.52, '20'], [23.81, '02'], [13.2, '18'], [7.8, '03'], [10.09, '05'], [10.8, '19'], [11.38, '01'], [6.75, '22'], [10.25, '08'], [7.17, '04'], [8.13, '00'], [9.02, '06'], [7.85, '07'], [11.05, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    hour = row[0]\n",
    "    avg_comment = row[1]\n",
    "    swap_avg_by_hour.append([avg_comment, hour])\n",
    "# Swapping position of time with avg comments per post\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.1 Top 5 Hours for Ask Posts Comments\n",
    "After finding the average number of comments per post based on the time of posting, we now want to focus on the top five times to post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.59, '15'], [23.81, '02'], [21.52, '20'], [16.8, '16']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking list sorted_swap\n",
    "print(sorted_swap[0:4], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 Hours for AskHN Comments \n",
      "\n",
      "15:00 38.59 - average comments per post.\n",
      "02:00 23.81 - average comments per post.\n",
      "20:00 21.52 - average comments per post.\n",
      "16:00 16.80 - average comments per post.\n",
      "21:00 16.01 - average comments per post.\n"
     ]
    }
   ],
   "source": [
    "# Sorting the values and printing the top 5 hours with the greatest number of comments. \n",
    "print(\"The top 5 Hours for AskHN Comments\", \"\\n\")\n",
    "for row in sorted_swap[0:5]:\n",
    "    hour = dt.datetime.strptime(row[1], '%H')\n",
    "    hour_str = hour.strftime('%H:%M')\n",
    "    avg = row[0]\n",
    "    output = (\"{0} {1:.2f} - average comments per post.\".format(hour_str, avg))\n",
    "    print(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glimpse of our list shows that the best time to post is at 15:00(3:00 pm) as it receives on average 38 comments per post. Suprisingly, posting at 15:00 is such a great time as there is about a sixty percent increase in comments received as compared to the second time of 02:00. \n",
    "\n",
    "One more important thing that needs to be looked at is what time zone the times are in as this can greatly affect our posts. From the documentation on the dataset, the times are in EST(Eastern Time Zone). With this taken into account we can now plan and develop content that would be posted at 15:00 EST. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "The purpose of this project was to find what type of post would receive the most engagement on HackerNews. After some quick comparisons between the AskHN, ShowHN, and other posts, we found that AskHN posts receive more comments on average. Our focus shifted to analyzing only AskHN posts and we found that by posting at 15:00 EST, there would be a higher probability to receive comments compared to posting at other times.\n",
    "\n",
    "<b>Therefore if one wanted to make a post on HackerNews and wanted that post to have a great probablity of receiving engagement (comments, shares) they should post at 15:00 EST. </b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
